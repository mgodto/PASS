# --- Add right after you create your full dataset and split it ---
from pathlib import Path
import numpy as np

results_dir = Path("results")
results_dir.mkdir(parents=True, exist_ok=True)

# If you used torch.utils.data.random_split -> you got Subset objects.
# Save their indices so evaluation can reuse the EXACT same split.
def _extract_indices(split_obj):
    # If using Subset, it has .indices
    if hasattr(split_obj, "indices"):
        return np.array(split_obj.indices)
    # Otherwise, assume it is a list/np.array already
    return np.asarray(split_obj, dtype=int)

np.save(results_dir / "train_indices.npy", _extract_indices(train_dataset))
np.save(results_dir / "test_indices.npy",  _extract_indices(test_dataset))

# Also save the class order so reports/labels match exactly.
try:
    classes = full_dataset.le.classes_.tolist()
except Exception:
    # Fallback to whatever you use to define your classes, e.g. dataset attribute
    classes = getattr(full_dataset, "classes", None)

if classes is not None:
    import numpy as _np
    _np.save(results_dir / "classes.npy", _np.array(classes, dtype=object))
    print("Saved classes.npy:", classes)
else:
    print("⚠️ Could not save classes.npy (no class list found).")
# --- End of patch ---
